{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80874,"databundleVersionId":8794587,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":886.289793,"end_time":"2024-08-16T01:07:48.747555","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-08-16T00:53:02.457762","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/muhammadnadhifn/rohlik-orders-forecasting-ensemble-stacking?scriptVersionId=203044968\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Copy from [0.0358 Ensemble + Stacking Modified (metamodel)](https://www.kaggle.com/code/pkuszboi/0-0358-ensemble-stacking-modified-metamodel) based on solution from [Ensemble + Stacking Modified (metamodel)](https://www.kaggle.com/code/wanyanwendi/ensemble-stacking-modified-metamodel) and [Fork of Ensemble + Stacking Modified](https://www.kaggle.com/code/dmitriych/fork-of-ensemble-stacking-modified?kernelSessionId=191085691) of [rohlik-starter-v1](https://www.kaggle.com/code/abdmental01/rohlik-starter-v1?kernelSessionId=188881811).\n<br>\n<br>\nRemove weightening on stacking model and add neural network as final stack prediction.\n<br>\n<br>\nInput Data -> Ensemble Model -> Stacking Model -> Neural Network -> Prediction Result","metadata":{"papermill":{"duration":0.007571,"end_time":"2024-08-16T00:53:05.36553","exception":false,"start_time":"2024-08-16T00:53:05.357959","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nfrom math import pi\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_percentage_error\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\nimport keras\n\n# Ignore all warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.747756,"end_time":"2024-08-16T00:53:11.120456","exception":false,"start_time":"2024-08-16T00:53:05.3727","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:03.800781Z","iopub.execute_input":"2024-10-24T09:46:03.801244Z","iopub.status.idle":"2024-10-24T09:46:22.588492Z","shell.execute_reply.started":"2024-10-24T09:46:03.801207Z","shell.execute_reply":"2024-10-24T09:46:22.587186Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-10-24 09:46:10.706020: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-10-24 09:46:10.706214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-10-24 09:46:10.867087: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"base_train_df = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/train.csv')\nbase_train_df.head(5)","metadata":{"papermill":{"duration":0.090698,"end_time":"2024-08-16T00:53:11.218642","exception":false,"start_time":"2024-08-16T00:53:11.127944","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.590863Z","iopub.execute_input":"2024-10-24T09:46:22.591638Z","iopub.status.idle":"2024-10-24T09:46:22.682053Z","shell.execute_reply.started":"2024-10-24T09:46:22.591604Z","shell.execute_reply":"2024-10-24T09:46:22.680569Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  warehouse        date  orders holiday_name  holiday  shutdown  \\\n0  Prague_1  2020-12-05  6895.0          NaN        0         0   \n1  Prague_1  2020-12-06  6584.0          NaN        0         0   \n2  Prague_1  2020-12-07  7030.0          NaN        0         0   \n3  Prague_1  2020-12-08  6550.0          NaN        0         0   \n4  Prague_1  2020-12-09  6910.0          NaN        0         0   \n\n   mini_shutdown  shops_closed  winter_school_holidays  school_holidays  \\\n0              0             0                       0                0   \n1              0             0                       0                0   \n2              0             0                       0                0   \n3              0             0                       0                0   \n4              0             0                       0                0   \n\n   blackout  mov_change  frankfurt_shutdown  precipitation  snow  \\\n0         0         0.0                   0            0.0   0.0   \n1         0         0.0                   0            0.0   0.0   \n2         0         0.0                   0            0.0   0.0   \n3         0         0.0                   0            0.8   0.0   \n4         0         0.0                   0            0.5   0.0   \n\n   user_activity_1  user_activity_2                   id  \n0           1722.0          32575.0  Prague_1_2020-12-05  \n1           1688.0          32507.0  Prague_1_2020-12-06  \n2           1696.0          32552.0  Prague_1_2020-12-07  \n3           1681.0          32423.0  Prague_1_2020-12-08  \n4           1704.0          32410.0  Prague_1_2020-12-09  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>warehouse</th>\n      <th>date</th>\n      <th>orders</th>\n      <th>holiday_name</th>\n      <th>holiday</th>\n      <th>shutdown</th>\n      <th>mini_shutdown</th>\n      <th>shops_closed</th>\n      <th>winter_school_holidays</th>\n      <th>school_holidays</th>\n      <th>blackout</th>\n      <th>mov_change</th>\n      <th>frankfurt_shutdown</th>\n      <th>precipitation</th>\n      <th>snow</th>\n      <th>user_activity_1</th>\n      <th>user_activity_2</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Prague_1</td>\n      <td>2020-12-05</td>\n      <td>6895.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1722.0</td>\n      <td>32575.0</td>\n      <td>Prague_1_2020-12-05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Prague_1</td>\n      <td>2020-12-06</td>\n      <td>6584.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1688.0</td>\n      <td>32507.0</td>\n      <td>Prague_1_2020-12-06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Prague_1</td>\n      <td>2020-12-07</td>\n      <td>7030.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1696.0</td>\n      <td>32552.0</td>\n      <td>Prague_1_2020-12-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Prague_1</td>\n      <td>2020-12-08</td>\n      <td>6550.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>1681.0</td>\n      <td>32423.0</td>\n      <td>Prague_1_2020-12-08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Prague_1</td>\n      <td>2020-12-09</td>\n      <td>6910.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1704.0</td>\n      <td>32410.0</td>\n      <td>Prague_1_2020-12-09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"base_test_df = pd.read_csv('/kaggle/input/rohlik-orders-forecasting-challenge/test.csv')\nbase_test_df.head(5)","metadata":{"papermill":{"duration":0.031192,"end_time":"2024-08-16T00:53:11.257609","exception":false,"start_time":"2024-08-16T00:53:11.226417","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.68371Z","iopub.execute_input":"2024-10-24T09:46:22.684141Z","iopub.status.idle":"2024-10-24T09:46:22.70854Z","shell.execute_reply.started":"2024-10-24T09:46:22.684107Z","shell.execute_reply":"2024-10-24T09:46:22.707199Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  warehouse        date holiday_name  holiday  shops_closed  \\\n0  Prague_1  2024-03-16          NaN        0             0   \n1  Prague_1  2024-03-17          NaN        0             0   \n2  Prague_1  2024-03-18          NaN        0             0   \n3  Prague_1  2024-03-19          NaN        0             0   \n4  Prague_1  2024-03-20          NaN        0             0   \n\n   winter_school_holidays  school_holidays                   id  \n0                       0                0  Prague_1_2024-03-16  \n1                       0                0  Prague_1_2024-03-17  \n2                       0                0  Prague_1_2024-03-18  \n3                       0                0  Prague_1_2024-03-19  \n4                       0                0  Prague_1_2024-03-20  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>warehouse</th>\n      <th>date</th>\n      <th>holiday_name</th>\n      <th>holiday</th>\n      <th>shops_closed</th>\n      <th>winter_school_holidays</th>\n      <th>school_holidays</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Prague_1</td>\n      <td>2024-03-16</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Prague_1_2024-03-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Prague_1</td>\n      <td>2024-03-17</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Prague_1_2024-03-17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Prague_1</td>\n      <td>2024-03-18</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Prague_1_2024-03-18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Prague_1</td>\n      <td>2024-03-19</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Prague_1_2024-03-19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Prague_1</td>\n      <td>2024-03-20</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Prague_1_2024-03-20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Base features\nbase_features = base_test_df.drop(columns=['id']).columns\ntest_id = base_test_df['id']","metadata":{"papermill":{"duration":0.020706,"end_time":"2024-08-16T00:53:11.286793","exception":false,"start_time":"2024-08-16T00:53:11.266087","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.710341Z","iopub.execute_input":"2024-10-24T09:46:22.710744Z","iopub.status.idle":"2024-10-24T09:46:22.722521Z","shell.execute_reply.started":"2024-10-24T09:46:22.710712Z","shell.execute_reply":"2024-10-24T09:46:22.721139Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.concat([base_train_df[base_features], base_train_df['orders']], axis=1)\ntrain_df = pd.concat([base_train_df[base_features], base_train_df['orders']], axis=1)\ntest_df = base_test_df[base_features]","metadata":{"papermill":{"duration":0.020238,"end_time":"2024-08-16T00:53:11.31491","exception":false,"start_time":"2024-08-16T00:53:11.294672","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.727201Z","iopub.execute_input":"2024-10-24T09:46:22.728069Z","iopub.status.idle":"2024-10-24T09:46:22.739867Z","shell.execute_reply.started":"2024-10-24T09:46:22.72799Z","shell.execute_reply":"2024-10-24T09:46:22.738517Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"papermill":{"duration":0.007575,"end_time":"2024-08-16T00:53:11.330277","exception":false,"start_time":"2024-08-16T00:53:11.322702","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Info of train or test datasets\nprint(train_df.info())\nprint('='*60)\nprint(test_df.info())","metadata":{"papermill":{"duration":0.036569,"end_time":"2024-08-16T00:53:11.374535","exception":false,"start_time":"2024-08-16T00:53:11.337966","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.741609Z","iopub.execute_input":"2024-10-24T09:46:22.741981Z","iopub.status.idle":"2024-10-24T09:46:22.776715Z","shell.execute_reply.started":"2024-10-24T09:46:22.741948Z","shell.execute_reply":"2024-10-24T09:46:22.775516Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7340 entries, 0 to 7339\nData columns (total 8 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   warehouse               7340 non-null   object \n 1   date                    7340 non-null   object \n 2   holiday_name            218 non-null    object \n 3   holiday                 7340 non-null   int64  \n 4   shops_closed            7340 non-null   int64  \n 5   winter_school_holidays  7340 non-null   int64  \n 6   school_holidays         7340 non-null   int64  \n 7   orders                  7340 non-null   float64\ndtypes: float64(1), int64(4), object(3)\nmemory usage: 458.9+ KB\nNone\n============================================================\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 397 entries, 0 to 396\nData columns (total 7 columns):\n #   Column                  Non-Null Count  Dtype \n---  ------                  --------------  ----- \n 0   warehouse               397 non-null    object\n 1   date                    397 non-null    object\n 2   holiday_name            17 non-null     object\n 3   holiday                 397 non-null    int64 \n 4   shops_closed            397 non-null    int64 \n 5   winter_school_holidays  397 non-null    int64 \n 6   school_holidays         397 non-null    int64 \ndtypes: int64(4), object(3)\nmemory usage: 21.8+ KB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Concat train data + test data\nall_df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)","metadata":{"papermill":{"duration":0.018558,"end_time":"2024-08-16T00:53:11.40267","exception":false,"start_time":"2024-08-16T00:53:11.384112","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.77838Z","iopub.execute_input":"2024-10-24T09:46:22.779485Z","iopub.status.idle":"2024-10-24T09:46:22.787961Z","shell.execute_reply.started":"2024-10-24T09:46:22.779431Z","shell.execute_reply":"2024-10-24T09:46:22.786863Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Convert the date column to a processable format \ndate_start = pd.to_datetime(all_df['date'], errors='coerce').min()\n\ndate_col = ['date']\nfor _col in date_col:\n    date_col = pd.to_datetime(all_df[_col], errors='coerce')\n    all_df[_col + \"_year\"] = date_col.dt.year.fillna(-1)\n    all_df[_col + \"_month\"] = date_col.dt.month.fillna(-1)\n    all_df[_col + \"_day\"] = date_col.dt.day.fillna(-1)\n    all_df[_col + \"_day_of_week\"] = date_col.dt.dayofweek.fillna(-1)\n    all_df[_col + \"_week_of_year\"] = date_col.dt.isocalendar().week.fillna(-1)\n\n    all_df[_col + \"_num\"] = (date_col-date_start).dt.days.fillna(-1)\n    #train['numday'] = (train['date']-date_start).dt.days\n    all_df[_col + \"_day_of_year\"] = date_col.dt.dayofyear.fillna(-1)\n    all_df[_col + \"_day_of_year\"] = np.where( (all_df[_col + \"_year\"]%4==0)&(all_df[_col + \"_month\"]>2), all_df[_col + \"_day_of_year\"]-1, all_df[_col + \"_day_of_year\"])\n\n    all_df[_col + \"_quarter\"] = date_col.dt.quarter.fillna(-1)\n    all_df[_col + \"_is_month_start\"] = date_col.dt.is_month_start.astype(int).fillna(-1)\n    all_df[_col + \"_is_month_end\"] = date_col.dt.is_month_end.astype(int).fillna(-1)\n    all_df[_col + \"_is_quarter_start\"] = date_col.dt.is_quarter_start.astype(int).fillna(-1)\n    all_df[_col + \"_is_quarter_end\"] = date_col.dt.is_quarter_end.astype(int).fillna(-1)\n    # all_df[_col + '_is_weekend'] = all_df['date_day_of_week'].isin([5, 6]).astype(int)\n    # all_df[_col + '_is_friday'] = all_df['date_day_of_week'].isin([4]).astype(int)\n    # all_df.drop(_col, axis=1, inplace=True)\n\nall_df['date'] = pd.to_datetime(all_df['date'])\nall_df","metadata":{"papermill":{"duration":0.071028,"end_time":"2024-08-16T00:53:11.48148","exception":false,"start_time":"2024-08-16T00:53:11.410452","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.789965Z","iopub.execute_input":"2024-10-24T09:46:22.790537Z","iopub.status.idle":"2024-10-24T09:46:22.86316Z","shell.execute_reply.started":"2024-10-24T09:46:22.790486Z","shell.execute_reply":"2024-10-24T09:46:22.861662Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       warehouse       date holiday_name  holiday  shops_closed  \\\n0       Prague_1 2020-12-05          NaN        0             0   \n1       Prague_1 2020-12-06          NaN        0             0   \n2       Prague_1 2020-12-07          NaN        0             0   \n3       Prague_1 2020-12-08          NaN        0             0   \n4       Prague_1 2020-12-09          NaN        0             0   \n...          ...        ...          ...      ...           ...   \n7732  Budapest_1 2024-05-11          NaN        0             0   \n7733  Budapest_1 2024-05-12          NaN        0             0   \n7734  Budapest_1 2024-05-13          NaN        0             0   \n7735  Budapest_1 2024-05-14          NaN        0             0   \n7736  Budapest_1 2024-05-15          NaN        0             0   \n\n      winter_school_holidays  school_holidays  orders  date_year  date_month  \\\n0                          0                0  6895.0       2020          12   \n1                          0                0  6584.0       2020          12   \n2                          0                0  7030.0       2020          12   \n3                          0                0  6550.0       2020          12   \n4                          0                0  6910.0       2020          12   \n...                      ...              ...     ...        ...         ...   \n7732                       0                0     NaN       2024           5   \n7733                       0                0     NaN       2024           5   \n7734                       0                0     NaN       2024           5   \n7735                       0                0     NaN       2024           5   \n7736                       0                0     NaN       2024           5   \n\n      date_day  date_day_of_week  date_week_of_year  date_num  \\\n0            5                 5                 49         0   \n1            6                 6                 49         1   \n2            7                 0                 50         2   \n3            8                 1                 50         3   \n4            9                 2                 50         4   \n...        ...               ...                ...       ...   \n7732        11                 5                 19      1253   \n7733        12                 6                 19      1254   \n7734        13                 0                 20      1255   \n7735        14                 1                 20      1256   \n7736        15                 2                 20      1257   \n\n      date_day_of_year  date_quarter  date_is_month_start  date_is_month_end  \\\n0                  339             4                    0                  0   \n1                  340             4                    0                  0   \n2                  341             4                    0                  0   \n3                  342             4                    0                  0   \n4                  343             4                    0                  0   \n...                ...           ...                  ...                ...   \n7732               131             2                    0                  0   \n7733               132             2                    0                  0   \n7734               133             2                    0                  0   \n7735               134             2                    0                  0   \n7736               135             2                    0                  0   \n\n      date_is_quarter_start  date_is_quarter_end  \n0                         0                    0  \n1                         0                    0  \n2                         0                    0  \n3                         0                    0  \n4                         0                    0  \n...                     ...                  ...  \n7732                      0                    0  \n7733                      0                    0  \n7734                      0                    0  \n7735                      0                    0  \n7736                      0                    0  \n\n[7737 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>warehouse</th>\n      <th>date</th>\n      <th>holiday_name</th>\n      <th>holiday</th>\n      <th>shops_closed</th>\n      <th>winter_school_holidays</th>\n      <th>school_holidays</th>\n      <th>orders</th>\n      <th>date_year</th>\n      <th>date_month</th>\n      <th>date_day</th>\n      <th>date_day_of_week</th>\n      <th>date_week_of_year</th>\n      <th>date_num</th>\n      <th>date_day_of_year</th>\n      <th>date_quarter</th>\n      <th>date_is_month_start</th>\n      <th>date_is_month_end</th>\n      <th>date_is_quarter_start</th>\n      <th>date_is_quarter_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Prague_1</td>\n      <td>2020-12-05</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6895.0</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>5</td>\n      <td>5</td>\n      <td>49</td>\n      <td>0</td>\n      <td>339</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Prague_1</td>\n      <td>2020-12-06</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6584.0</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>6</td>\n      <td>6</td>\n      <td>49</td>\n      <td>1</td>\n      <td>340</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Prague_1</td>\n      <td>2020-12-07</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7030.0</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>7</td>\n      <td>0</td>\n      <td>50</td>\n      <td>2</td>\n      <td>341</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Prague_1</td>\n      <td>2020-12-08</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6550.0</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>8</td>\n      <td>1</td>\n      <td>50</td>\n      <td>3</td>\n      <td>342</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Prague_1</td>\n      <td>2020-12-09</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6910.0</td>\n      <td>2020</td>\n      <td>12</td>\n      <td>9</td>\n      <td>2</td>\n      <td>50</td>\n      <td>4</td>\n      <td>343</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7732</th>\n      <td>Budapest_1</td>\n      <td>2024-05-11</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2024</td>\n      <td>5</td>\n      <td>11</td>\n      <td>5</td>\n      <td>19</td>\n      <td>1253</td>\n      <td>131</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7733</th>\n      <td>Budapest_1</td>\n      <td>2024-05-12</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2024</td>\n      <td>5</td>\n      <td>12</td>\n      <td>6</td>\n      <td>19</td>\n      <td>1254</td>\n      <td>132</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7734</th>\n      <td>Budapest_1</td>\n      <td>2024-05-13</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2024</td>\n      <td>5</td>\n      <td>13</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1255</td>\n      <td>133</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7735</th>\n      <td>Budapest_1</td>\n      <td>2024-05-14</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2024</td>\n      <td>5</td>\n      <td>14</td>\n      <td>1</td>\n      <td>20</td>\n      <td>1256</td>\n      <td>134</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7736</th>\n      <td>Budapest_1</td>\n      <td>2024-05-15</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>2024</td>\n      <td>5</td>\n      <td>15</td>\n      <td>2</td>\n      <td>20</td>\n      <td>1257</td>\n      <td>135</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7737 rows × 20 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Apply sine and cosine transformations\n#all_df['year_sin'] = all_df['date_year'] * np.sin(2 * pi * all_df['date_year'])\n#all_df['year_cos'] = all_df['date_year'] * np.cos(2 * pi * all_df['date_year'])\nall_df['month_sin'] = all_df['date_month'] * np.sin(2 * pi * all_df['date_month'])\nall_df['month_cos'] = all_df['date_month'] * np.cos(2 * pi * all_df['date_month'])\nall_df['day_sin'] = all_df['date_day'] * np.sin(2 * pi * all_df['date_day'])\nall_df['day_cos'] = all_df['date_day'] * np.cos(2 * pi * all_df['date_day'])\n\nall_df['year_sin'] = np.sin(2 * pi * all_df[\"date_day_of_year\"])\nall_df['year_cos'] = np.cos(2 * pi * all_df['date_day_of_year'])\n","metadata":{"papermill":{"duration":0.023917,"end_time":"2024-08-16T00:53:11.515287","exception":false,"start_time":"2024-08-16T00:53:11.49137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.864817Z","iopub.execute_input":"2024-10-24T09:46:22.865224Z","iopub.status.idle":"2024-10-24T09:46:22.882151Z","shell.execute_reply.started":"2024-10-24T09:46:22.86519Z","shell.execute_reply":"2024-10-24T09:46:22.8808Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Replace Null values with None\nall_df['holiday_name'].fillna('None', inplace=True)","metadata":{"papermill":{"duration":0.017391,"end_time":"2024-08-16T00:53:11.541253","exception":false,"start_time":"2024-08-16T00:53:11.523862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.88404Z","iopub.execute_input":"2024-10-24T09:46:22.884981Z","iopub.status.idle":"2024-10-24T09:46:22.892431Z","shell.execute_reply.started":"2024-10-24T09:46:22.884924Z","shell.execute_reply":"2024-10-24T09:46:22.891101Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# OneHotEncoding → holiday_name\nenc = OneHotEncoder( sparse=False )\n\nholiday_encoded = enc.fit_transform(all_df[['holiday_name']])\nencoded_df = pd.DataFrame(holiday_encoded, columns=enc.get_feature_names_out(['holiday_name']))\nall_df = pd.concat([all_df, encoded_df], axis=1)\n\n# drop holiday_name column\nall_df = all_df.drop('holiday_name', axis=1)","metadata":{"papermill":{"duration":0.034467,"end_time":"2024-08-16T00:53:11.584312","exception":false,"start_time":"2024-08-16T00:53:11.549845","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.894195Z","iopub.execute_input":"2024-10-24T09:46:22.894621Z","iopub.status.idle":"2024-10-24T09:46:22.921465Z","shell.execute_reply.started":"2024-10-24T09:46:22.894584Z","shell.execute_reply":"2024-10-24T09:46:22.920142Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# LabelEncoding → warehouse column\nle = preprocessing.LabelEncoder()\n\nall_df['warehouse'] = le.fit_transform(all_df['warehouse'])\n\n# holiday_name\n# all_df['holiday_name'] = le.fit_transform(all_df['holiday_name'])","metadata":{"papermill":{"duration":0.018637,"end_time":"2024-08-16T00:53:11.611444","exception":false,"start_time":"2024-08-16T00:53:11.592807","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.922979Z","iopub.execute_input":"2024-10-24T09:46:22.923383Z","iopub.status.idle":"2024-10-24T09:46:22.932931Z","shell.execute_reply.started":"2024-10-24T09:46:22.92335Z","shell.execute_reply":"2024-10-24T09:46:22.931344Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Obtain the data for the day before or after a holiday\nall_df['holiday_before'] = all_df['holiday'].shift(1).fillna(0).astype(int)\nall_df['holiday_after'] = all_df['holiday'].shift(-1).fillna(0).astype(int)\n\n# all_df['holiday_shop_closed'] = all_df['holiday'] * all_df['shops_closed']\n\n# Obtain the data for the day before or after a shops_closed → It did not lead to an improvement in the MAPE score\n# all_df['shops_closed_before'] = all_df['shops_closed'].shift(1).fillna(0).astype(int)\n# all_df['shops_closed_after'] = all_df['shops_closed'].shift(-1).fillna(0).astype(int)\n\n# Obtain the data for the day before or after school_holidays → It did not lead to an improvement in the MAPE score\n# all_df['winter_school_holidays_before'] = all_df['winter_school_holidays'].shift(1).fillna(0).astype(int)\n# all_df['winter_school_holidays_after'] = all_df['winter_school_holidays'].shift(-1).fillna(0).astype(int)\n# all_df['school_holidays_before'] = all_df['school_holidays'].shift(1).fillna(0).astype(int)\n# all_df['school_holidays_after'] = all_df['school_holidays'].shift(-1).fillna(0).astype(int)\n\n# Obtain the data for the day before or after weekends → It did not lead to an improvement in the MAPE score\n# all_df['weekend_before'] = all_df['date_is_weekend'].shift(1).fillna(0).astype(int)\n# all_df['weekend_after'] = all_df['date_is_weekend'].shift(-1).fillna(0).astype(int)","metadata":{"papermill":{"duration":0.020223,"end_time":"2024-08-16T00:53:11.640297","exception":false,"start_time":"2024-08-16T00:53:11.620074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.934582Z","iopub.execute_input":"2024-10-24T09:46:22.935002Z","iopub.status.idle":"2024-10-24T09:46:22.946794Z","shell.execute_reply.started":"2024-10-24T09:46:22.934969Z","shell.execute_reply":"2024-10-24T09:46:22.945351Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Convert the data back to train_df and test_df\ntrain_df_le = all_df[~all_df['orders'].isnull()]\ntest_df_le = all_df[all_df['orders'].isnull()]\n\ntrain_df_le = train_df_le.drop(columns=['date'], axis=1)\ntest_df_le = test_df_le.drop(columns=['date'], axis=1)","metadata":{"papermill":{"duration":0.023858,"end_time":"2024-08-16T00:53:11.672448","exception":false,"start_time":"2024-08-16T00:53:11.64859","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.953083Z","iopub.execute_input":"2024-10-24T09:46:22.953511Z","iopub.status.idle":"2024-10-24T09:46:22.971888Z","shell.execute_reply.started":"2024-10-24T09:46:22.953477Z","shell.execute_reply":"2024-10-24T09:46:22.970734Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Modeling (Ensemble + Stacking)","metadata":{"papermill":{"duration":0.008452,"end_time":"2024-08-16T00:53:11.71433","exception":false,"start_time":"2024-08-16T00:53:11.705878","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Ensemble**\n* LightGBM \n* XGBoost \n* RandomForest \n* CatBoost\n* Logistic Regression\n* Ada Boost\n* Decision Tree\n* Gradient Boost","metadata":{"papermill":{"duration":0.008416,"end_time":"2024-08-16T00:53:11.731192","exception":false,"start_time":"2024-08-16T00:53:11.722776","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# split train data\n\n# Set random seed \nrandom_seed = 777 \n\nX = train_df_le.drop(columns=['orders'])\ny = train_df_le['orders']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1, random_state=random_seed)","metadata":{"papermill":{"duration":0.025545,"end_time":"2024-08-16T00:53:11.766097","exception":false,"start_time":"2024-08-16T00:53:11.740552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.973333Z","iopub.execute_input":"2024-10-24T09:46:22.973667Z","iopub.status.idle":"2024-10-24T09:46:22.992766Z","shell.execute_reply.started":"2024-10-24T09:46:22.973637Z","shell.execute_reply":"2024-10-24T09:46:22.991449Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Cross validation\n\n# Number of splits for cross-validation\nn_splits = 10\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n\n# Placeholders for stacking features\nstacking_train = np.zeros((X_train.shape[0], 8))\nstacking_test = np.zeros((X_test.shape[0],8))\n\n# Initialize base models\nlgb_model = lgb.LGBMRegressor(random_state=random_seed)\nxgb_model = xgb.XGBRegressor(random_state=random_seed)\ncat_model = CatBoostRegressor(silent=True, random_state=random_seed)\nrf_model = RandomForestRegressor(random_state=random_seed)\nlr_model = LogisticRegression(random_state=random_seed)\nad_model = AdaBoostRegressor(random_state=random_seed)\ndt_model = DecisionTreeRegressor(random_state=random_seed)\ngb_model = GradientBoostingRegressor(random_state=random_seed)\n\n# Train base models with cross-validation\nfor train_idx, val_idx in kf.split(X_train):\n    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    # Train each base model\n    lgb_model.fit(X_tr, y_tr)\n    xgb_model.fit(X_tr, y_tr)\n    cat_model.fit(X_tr, y_tr)\n    rf_model.fit(X_tr, y_tr)\n    lr_model.fit(X_tr, y_tr)\n    ad_model.fit(X_tr, y_tr)\n    dt_model.fit(X_tr, y_tr)\n    gb_model.fit(X_tr, y_tr)\n\n    # Predict on validation set\n    stacking_train[val_idx, 0] = lgb_model.predict(X_val)\n    stacking_train[val_idx, 1] = xgb_model.predict(X_val)\n    stacking_train[val_idx, 2] = cat_model.predict(X_val)\n    stacking_train[val_idx, 3] = rf_model.predict(X_val)\n    stacking_train[val_idx, 4] = lr_model.predict(X_val)\n    stacking_train[val_idx, 5] = ad_model.predict(X_val)\n    stacking_train[val_idx, 6] = dt_model.predict(X_val)\n    stacking_train[val_idx, 7] = gb_model.predict(X_val)\n\n    # Predict on test set\n    stacking_test[:, 0] += lgb_model.predict(X_test) / n_splits\n    stacking_test[:, 1] += xgb_model.predict(X_test) / n_splits\n    stacking_test[:, 2] += cat_model.predict(X_test) / n_splits\n    stacking_test[:, 3] += rf_model.predict(X_test) / n_splits\n    stacking_test[:, 4] += lr_model.predict(X_test) / n_splits\n    stacking_test[:, 5] += ad_model.predict(X_test) / n_splits\n    stacking_test[:, 6] += dt_model.predict(X_test) / n_splits\n    stacking_test[:, 7] += gb_model.predict(X_test) / n_splits\n    \n\n# Train meta-model\n# meta_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n# meta_model =\nmeta_model_1 = LGBMRegressor(n_estimators=150, num_leaves=15, learning_rate=0.05, colsample_bytree=0.6, lambda_l1=0.2, lambda_l2=0.2, random_state=random_seed)\nmeta_model_2 = CatBoostRegressor(verbose=0, random_state = random_seed)\nmeta_model_3 = XGBRegressor(random_state = random_seed)\n\nmeta_model_1.fit(stacking_train, y_train)\nmeta_model_2.fit(stacking_train, y_train)\nmeta_model_3.fit(stacking_train, y_train)\n\nbest_iteration_1 = meta_model_1.best_iteration_\nbest_iteration_2 = meta_model_2.best_iteration_\n\nmeta_train_1 = meta_model_1.predict(stacking_train)\nmeta_train_2 = meta_model_2.predict(stacking_train)\nmeta_train_3 = meta_model_2.predict(stacking_train)\n\n# Train Neural Network Model\n\nmeta_train = np.vstack([meta_train_1, meta_train_2, meta_train_3]).T\n\nnn_model = keras.models.Sequential([\n    keras.layers.Dense(64, activation='relu', input_dim=3),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(1)\n])\nnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\nnn_model.summary()\nnn_model.fit(meta_train, y_train, epochs=10, batch_size=1)","metadata":{"papermill":{"duration":875.863225,"end_time":"2024-08-16T01:07:47.638539","exception":false,"start_time":"2024-08-16T00:53:11.775314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T09:46:22.994739Z","iopub.execute_input":"2024-10-24T09:46:22.995224Z","iopub.status.idle":"2024-10-24T10:06:53.070315Z","shell.execute_reply.started":"2024-10-24T09:46:22.995182Z","shell.execute_reply":"2024-10-24T10:06:53.068994Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003331 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 980\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n[LightGBM] [Info] Start training from score 5540.911128\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007589 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 983\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5534.855261\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 983\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5533.542316\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 985\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5534.330507\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007651 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 980\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5528.689780\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 983\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5544.863588\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007668 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 982\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n[LightGBM] [Info] Start training from score 5551.502044\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005920 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 983\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 27\n[LightGBM] [Info] Start training from score 5526.702195\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 980\n[LightGBM] [Info] Number of data points in the train set: 6605, number of used features: 26\n[LightGBM] [Info] Start training from score 5533.006964\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007447 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 986\n[LightGBM] [Info] Number of data points in the train set: 6606, number of used features: 27\n[LightGBM] [Info] Start training from score 5526.058734\n[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001756 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1906\n[LightGBM] [Info] Number of data points in the train set: 7339, number of used features: 8\n[LightGBM] [Info] Start training from score 5535.446110\n[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 4.8269\nEpoch 2/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 3.0374\nEpoch 3/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 3.1129\nEpoch 4/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.9361\nEpoch 5/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.8291\nEpoch 6/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.9809\nEpoch 7/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.8702\nEpoch 8/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.9013\nEpoch 9/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.8072\nEpoch 10/10\n\u001b[1m7339/7339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 2.8296\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79e7469867d0>"},"metadata":{}}]},{"cell_type":"code","source":"# Predict on test set using meta-model with NN\nmeta_pred_1 = meta_model_1.predict(stacking_test)\nmeta_pred_2 = meta_model_2.predict(stacking_test)\nmeta_pred_3 = meta_model_3.predict(stacking_test)\n\nmeta_pred = np.vstack([meta_pred_1, meta_pred_2, meta_pred_3]).T\n\nnn_pred = nn_model.predict(meta_pred)\n\nmape = mean_absolute_percentage_error(y_test, nn_pred)\nprint(f'Simple Average Ensemble Model MAPE: {mape:.4f}')\n\n# MAPE: 0.0000","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:06:53.071953Z","iopub.execute_input":"2024-10-24T10:06:53.072461Z","iopub.status.idle":"2024-10-24T10:06:53.221818Z","shell.execute_reply.started":"2024-10-24T10:06:53.072425Z","shell.execute_reply":"2024-10-24T10:06:53.220692Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\nSimple Average Ensemble Model MAPE: 0.0385\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction\n# test_df_le = test_df_le.drop(columns=['date', 'orders'])\ntest_df_le = test_df_le.drop(columns=['orders'])\n\nlgb_pred_test = lgb_model.predict(test_df_le)\nxgb_pred_test = xgb_model.predict(test_df_le)\ncat_pred_test = cat_model.predict(test_df_le)\nrf_pred_test = rf_model.predict(test_df_le)\nlr_pred_test = lr_model.predict(test_df_le)\nad_pred_test = ad_model.predict(test_df_le)\ndt_pred_test = dt_model.predict(test_df_le)\ngb_pred_test = gb_model.predict(test_df_le)\n\n# stacking_test_df_le = np.vstack([lgb_pred_test, xgb_pred_test, cat_pred_test, rf_pred_test]).T\nstacking_test_df_le = np.vstack([lgb_pred_test, xgb_pred_test, cat_pred_test, rf_pred_test, lr_pred_test, ad_pred_test, dt_pred_test, gb_pred_test]).T\n\nmeta_test_pred_1 = meta_model_1.predict(stacking_test_df_le)\nmeta_test_pred_2 = meta_model_2.predict(stacking_test_df_le)\nmeta_test_pred_3 = meta_model_3.predict(stacking_test_df_le)\n\nmeta_test_pred = np.vstack([meta_test_pred_1, meta_test_pred_2, meta_test_pred_3]).T\n\nsubmit_pred = nn_model.predict(meta_test_pred)","metadata":{"papermill":{"duration":0.115884,"end_time":"2024-08-16T01:07:47.790594","exception":false,"start_time":"2024-08-16T01:07:47.67471","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T10:06:53.223096Z","iopub.execute_input":"2024-10-24T10:06:53.223432Z","iopub.status.idle":"2024-10-24T10:06:53.574121Z","shell.execute_reply.started":"2024-10-24T10:06:53.223403Z","shell.execute_reply":"2024-10-24T10:06:53.572905Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] lambda_l2 is set=0.2, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2\n[LightGBM] [Warning] lambda_l1 is set=0.2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submit","metadata":{"papermill":{"duration":0.021856,"end_time":"2024-08-16T01:07:47.849923","exception":false,"start_time":"2024-08-16T01:07:47.828067","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_id,\n    'Target': submit_pred.flatten()\n})\n\n# Save\nsubmission.to_csv('submission.csv', index=False)\n\nprint(submission)","metadata":{"papermill":{"duration":0.026577,"end_time":"2024-08-16T01:07:47.895677","exception":false,"start_time":"2024-08-16T01:07:47.8691","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-24T10:06:53.578859Z","iopub.execute_input":"2024-10-24T10:06:53.579261Z","iopub.status.idle":"2024-10-24T10:06:53.593484Z","shell.execute_reply.started":"2024-10-24T10:06:53.579228Z","shell.execute_reply":"2024-10-24T10:06:53.592417Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"                        id        Target\n0      Prague_1_2024-03-16  10515.565430\n1      Prague_1_2024-03-17  10330.381836\n2      Prague_1_2024-03-18  10178.464844\n3      Prague_1_2024-03-19   9721.095703\n4      Prague_1_2024-03-20   9666.975586\n..                     ...           ...\n392  Budapest_1_2024-05-11   7068.773438\n393  Budapest_1_2024-05-12   6642.862793\n394  Budapest_1_2024-05-13   6806.291992\n395  Budapest_1_2024-05-14   6909.515137\n396  Budapest_1_2024-05-15   6656.133789\n\n[397 rows x 2 columns]\n","output_type":"stream"}]}]}